Tema;Pregunta;Respuesta 1;Respuesta 2;Respuesta 3;Respuesta 4;Respuesta correcta;Porque
1;¿Por qué se considera que el enfoque de IA en la nube es ágil?;A. Porque los entornos de trabajo que facilita el proveedor de nube se ejecutan más rápidamente que su equivalente en un centro de datos.;B. Porque las capacidades de IA pueden provisionarse en minutos.;C. Porque es sencillo decidir qué proveedor de nube utilizar, independientemente del caso de uso o las necesidades específicas.;D. Porque el acceso a los servicios de IA puede realizarse directamente desde un navegador web.;b;La provisión ágil de servicios de IA es fundamental para que el foco de la organización sea la resolución efectiva de problemáticas de negocio con IA, no las actividades de puesta en marcha de la infraestructura necesaria.
1;¿En qué consiste la ingeniería de variables en AutoML?;A. En normalizar los valores de cada variable existente en el dataset.;B. Es la única actividad para la que el AutoML no proporciona ningún tipo de automatización.;C. En la clasificación automática de las variables existentes y la detección de su grado de importancia, así como la generación de nuevas variables.;D. Consiste en identificar el significado de cada variable en el contexto del caso de uso que se pretender resolver con el modelo de IA.;c;La ingeniería de variables es una de las actividades clave en el proceso de generación de modelos eficaces. Por eso, las capacidades de automatización que provee el AutoML son muy útiles a la hora de abordarla.
1;¿Qué porcentaje de entornos de nube dispone en la actualidad de servicios de IA contratados según Wiz Research?;En torno al 70 %.;B. En torno al 99 %.;C. En torno al 25 %.;D. Residual, prácticamente el 0 %.;a;La utilización de servicios de IA en la nube era prácticamente impensable hace varios años. Sin embargo, es importante ser consciente de que en la actualidad el grado de adopción es muy alto.
1;¿Cuál es uno de los beneficios de contratar servicios de IA en la nube?;A. Que el coste es siempre menor respecto a la provisión de capacidades de IA en un centro de datos propio.;B. Que parte del trabajo de creación de modelos lo realizan los ingenieros del proveedor.;C. Que en general se obtienen mejores rendimientos en los modelos proporcionados por el proveedor respecto a los que podemos crear nosotros.;D. El consumo de modelos preentrenados por el proveedor para resolver problemáticas conocidas.;d;El entrenamiento de modelos con datos masivos implica un coste, esfuerzo y tiempo que muchas organizaciones no pueden asumir. Por eso, la disponibilidad de modelos preentrenados es una gran ventaja que ofrecen los proveedores de nube.
1;¿Cuál es un escenario en el que se recomienda desplegar capacidades de IA on premise en lugar de hacerlo a través de un proveedor de nube?;A. Cuando se dispone de un presupuesto bajo.;B. Si el grado de personalización que se requiere es elevado.;C. Cuando solo se desea experimentar con la IA, pero aún no hay grado de madurez suficiente para llevarla a producción.;D. Cuando no dispongamos de personal suficientemente especializado.;b;Muchas de las ventajas de los proveedores de nube proceden de la industrialización de sus servicios de IA. Sin embargo, esto implica que el margen de personalización es estrecho, y si nuestro caso de uso tiene particularidades muy específicas, es posible que los proveedores de nube no puedan satisfacerlas.
1;¿Cuál de los siguientes es un requisito exigible al proveedor en materia de seguridad?;A. La separación de entornos: desarrollo, preproducción y producción.;B. El uso de VPNs para acceder a los servicios de IA de forma segura.;C. La auditoría de los datos que subimos a sus servicios para garantizar que no incumplen regulaciones de privacidad.;D. Cumplimiento de estándares de seguridad y posesión de certificaciones relacionadas con seguridad.;d;El hecho de que un tercero independiente haya certificado las prácticas de seguridad del proveedor de nube es una garantía considerable de que los datos y modelos con los que trabajemos estarán suficientemente protegidos.
1;¿Cuál de los siguientes es un requisito de seguridad que debe adoptar la propia organización que contrata servicios de IA en la nube?;A. El parcheado de los sistemas a través de los cuales se prestan los servicios de IA.;B. La actualización de los sistemas operativos en los servidores.;C. Establecer una correcta separación de privilegios para que cada usuario solo tenga acceso a la información y funcionalidades que necesita.;D. La disponibilidad de mecanismos de autenticación robustos para acceder a los servicios de IA.;c;En el modelo de responsabilidad compartida, es el cliente quien tiene que determinar qué usuarios pueden acceder a qué datos y funcionalidades de los servicios de IA contratados.
1;¿Cuál es una de las características diferenciales de los principales proveedores de nube en relación con proveedores de nicho en el ámbito de IA?;A. La disponibilidad de modelos preentrenados.;B. La integración con el resto de los servicios de computación en la nube, lo que permite construir una solución de negocio con un único proveedor.;C. Las capacidades de AutoML.;D. Las capacidades de visión artificial.;b;Es más sencillo integrar los servicios de IA con otros servicios de computación en la nube del mismo proveedor, porque esta integración ya existe y solo debe parametrizarse para que empiece a funcionar.
1;¿Para qué sirve la etapa de extracción de tókenes en los sistemas de procesamiento del lenguaje natural?;A. Para detectar de palabras, expresiones o símbolos clave que permitan esclarecer la intención del mensaje.;B. Para revisar ortográficamente el contenido del mensaje.;C. Para transformar el mensaje en código fuente interpretable por una máquina.;D. Para descartar el contenido irrelevante del mensaje.;a;El proceso de comprensión de un mensaje escrito en lenguaje natural es complejo, por lo que debe dividirse en fases. La primera de estas fases, la extracción de tókenes, es la clave para tener una primera visión de la intención de dicho mensaje.
1;¿En qué consiste la minimización de datos en relación con la privacidad?;A. Consiste en utilizar el menor volumen de datos posible para reducir el impacto de una brecha que afecte a la privacidad.;B. Consiste en reducir el rango de las variables numéricas para evitar cifras elevadas que pueden interferir con los algoritmos de IA utilizados.;C. Consiste en comprimir los datos antes de enviarlos al servicio de IA.;D. Consiste en utilizar únicamente variables relevantes en el proceso de entrenamiento, evitando aquellas que puedan generar sesgos con perjuicio para las personas.;d;Incorporar variables irrelevantes implica un esfuerzo y coste adicional, que además pueden desencadenar incumplimientos regulatorios o generación de predicciones que perjudican a un colectivo de personas.
1;Mod e - p1 Principal ventaja de los Jupyter Notebooks;A. Que son fáciles de usar.;B. Ejecutar paso a paso y combinar código + resultados en un único documento.;C. Que son gratuitos.;D. Que están disponibles en todos los idiomas.;b;Permiten ejecutar el análisis paso a paso y documentarlo en el mismo cuaderno, combinando código y resultados para iterar y depurar fácilmente.
1;Mod e - p2 ¿A qué tipo de usuarios se dirigen estos servicios?;A. A usuarios que no tienen conocimientos de IA.;B. Expertos en ciencia de datos e IA.;C. A usuarios que quieren utilizar la IA para fines personales.;D. A usuarios que quieren aprender a programar.;b;Están orientados a perfiles especializados (científicos de datos/IA) que necesitan un entorno flexible para explorar, entrenar y validar modelos.
1;Mod e - p3 ¿Qué permite hacer la IA responsable en AutoML?;A. Garantizar que la IA se utilice para fines éticos.;B. Detectar sesgos en los datos.;C. Reducir la probabilidad de incidentes de seguridad.;D. Controlar el acceso a los modelos de IA.;b;Aporta controles para identificar sesgos y uso indebido de datos durante el proceso automático de creación del modelo, mejorando fiabilidad y cumplimiento.
1;Mod e - p9 Principal característica de AutoML;A. Diseñar modelos sin programar / sin conocimientos especializados.;B. Es una técnica exclusiva de Azure Machine Learning.;C. Únicamente se puede utilizar desde una interfaz gráfica.;D. Garantiza la creación del modelo más preciso posible.;a;Automatiza el diseño y entrenamiento de modelos para que puedan crearse soluciones personalizadas sin programar ni tener conocimientos avanzados de ciencia de datos.
1;Mod d - p1 ¿Qué permiten hacer los servicios de visión artificial?;A. Reconocer la voz de las personas.;B. Traducir textos a diferentes idiomas.;C. Generar textos a partir de imágenes.;D. Identificar objetos, personas y acciones en imágenes.;D;El tema define visión artificial como identificación de objetos/personas/acciones (y otros patrones) en imágenes/vídeo.
1;Mod d - p2 ¿Qué es el análisis de sentimientos?;A. El análisis de las emociones de las personas.;B. El análisis del estado de ánimo de las personas.;C. La detección del tono de un mensaje.;D. El análisis de la personalidad de las personas.;C;El tema lo define como detección del tono (positivo/negativo/neutro) del mensaje.
1;Mod d - p3 ¿Cuál es uno de los fines habituales de los servicios de procesamiento del lenguaje?;A. Conversión de voz a texto.;B. Reconocimiento facial;C. Detección de objetos;D. Generación de imágenes;A;El tema lista como fin habitual la conversión de audio a texto dentro de NLP.
2;¿Qué métodos se pueden utilizar para enviar ficheros o carpetas a un bucket de Google Cloud Storage?;A. Se debe utilizar el cliente pesado facilitado por Google, que puede descargarse en el sitio web de Google Cloud.;B. Google Cloud Console, línea de comandos, REST API.;C. Solamente Google Cloud Console.;D. Únicamente REST API, como medida de seguridad para evitar fugas de datos sensibles.;b;Google ofrece los tres métodos para enviar ficheros a GCS. El primero es un método interactivo, mientras que los otros dos se utilizan desde scripts o código fuente, respectivamente.
2;Google Cloud Storage es un servicio de almacenamiento basado en:;A. Ficheros.;B. Objetos.;C. Bloques.;D. Columnas.;b;Google Cloud Storage es un sistema de almacenamiento basado en objetos. Este enfoque permite escalabilidad masiva, menos complejidad y búsquedas más eficientes y rápidas.
2;¿Cuál de las siguientes es una ventaja de los cuadernos gestionados por el usuario?;A. No requieren reinicio tras un cambio de la VM en la que se ejecutan.;B. Admiten un mayor grado de personalización que los cuadernos gestionados por Google.;C. Reducen las opciones de personalización para proporcionar mayor seguridad.;D. En general, se ejecutan con menor latencia que los cuadernos gestionados por Google.;b;La característica diferencial de los cuadernos gestionados por el usuario es precisamente su elevado grado de personalización, con el propósito de acomodar casuísticas no contempladas por las configuraciones estándar de AI Workbench.
2;¿Qué lenguajes de programación están soportados en Google AutoML?;A. Java, Python y Rust.;B. Ninguno, porque AutoML no requiere escribir código fuente para entrenar modelos.;C. Java y Python.;D. Solo Python, que es lenguaje más habitual en los Jupyter Notebooks.;b;En efecto, AutoML es una plataforma no code que no requiere programación para generar modelos. Por tanto, no soporta ninguno de los lenguajes, porque no son necesarios para su operativa.
2;¿Cuál de las siguientes no es una métrica de optimización (optimization objective) para un modelo de regresión creado con Google AutoML?;A. RMSE.;B. AUC ROC.;C. MAE.;D. RMSLE.;b;La métrica de área bajo la curva del receiver-operating characteristic (AUC ROC) se utiliza en tareas de clasificación, no de regresión.
2;¿Qué tratamiento se aplica a las variables categóricas en el proceso de transformación de datos de Google AutoML?;A. Se genera un embedding asociado a cada valor de la variable categórica.;B. Se genera un índice por cada valor y un embedding asociado al índice.;C. No se realiza ningún tratamiento, se utilizan los valores tal cual aparecen en el dataset.;D. Se asigna un valor entero correlativo a cada valor encontrado.;b;Este tratamiento permite asociar vectores numéricos que no presuponen relaciones entre los valores de la variable categórica, como sí ocurre con la asignación de números enteros consecutivos (índices).
2;¿Cuál de las siguientes no es una opción de configuración de CREATE MODEL para el proceso de entrenamiento en BigQuery ML?;A. Número máximo de iteraciones.;B. Ratio de varianza total explicada.;C. Tipo de modelo.;D. Parámetros de regularización L1 y L2.;b;El ratio de varianza total explicada es un dato que proporciona la función ML.EVALUATE() cuando se ejecuta sobre un modelo PCA. No tiene nada que ver con las opciones de configuración de CREATE MODEL.
2;¿Cuál es la característica diferencial de la técnica bayesian optimization?;A. Que prueba exhaustivamente todas las combinaciones posibles.;B. Que es capaz de seleccionar las combinaciones más prometedoras para maximizar el rendimiento.;C. Que elige aleatoriamente qué combinaciones probar para hacer que el proceso de optimización sea computacionalmente viable.;D. Que elige qué combinaciones probar a partir de reglas que especifica el usuario.;b;El uso de estadística bayesiana permite aprender de las combinaciones ya probadas para determinar qué dirección seguir, es decir, qué combinaciones deberían probarse a continuación para obtener los mejores resultados.
2;¿Cuál es el espacio de soluciones de neural architecture search?;A. Los posibles valores de hiperparámetros de la red neuronal.;B. Los posibles diseños de arquitectura de la red neuronal.;C. Los valores de parámetros que se ajustarán en el proceso de entrenamiento de la red neuronal.;D. Ninguno de los anteriores.;b;El NAS es un sistema que genera arquitecturas de redes neuronales y prueba cuál de ellas ofrece mejores resultados para una tarea dada. Por contra, los valores de hiperparámetros se determinan en el proceso de ajuste o tuning.
2;¿En qué se diferencian los métodos de integrated gradients y XRAI para determinar las regiones de una imagen que más contribuyen al resultado de la clasificación?;"A. Integrated gradients identifica áreas de la imagen; XRAI identifica píxeles.";"B. Integrated gradients identifica píxeles; XRAI identifica áreas de la imagen.";C. XRAI es una variante de integrated gradients que se ejecuta más rápido.;D. Integrated gradients es una versión mejorada de XRAI.;b;XRAI es una variante de integrated gradients que produce resultados más fácilmente interpretables, porque en lugar de señalar píxeles aislados en una imagen, determina las regiones de una imagen que más contribuyen al resultado de la clasificación.
2;Mod C – P2. ¿En qué consiste la ingeniería de variables en AutoML?;A. En normalizar los valores de cada variable existente en el dataset;"B. Es la única actividad para la que el AutoML no proporciona ningún tipo de
automatización";C. En la clasificación automática de las variables existentes y la detección de su grado de importancia, así como la generación de nuevas variables.;"D. Consiste en identificar el significado de cada variable en el contexto del caso de uso
que se pretender resolver con el modelo de IA.";C;AutoML automatiza etapas como ingeniería de variables (definición de AutoML) , y durante el entrenamiento Vertex AI identifica automáticamente la tipología de variables y aplica transformaciones (texto→n-grams, temporales→año/mes/día, etc.) y luego reporta importancia de variables en “Evaluation details”.
2;Mod E – P4. ¿Qué técnica de explicabilidad se utiliza en árboles de decisión y determina la reducción de impureza…?;A. SHAP;B. Permutation feature importance;C. GINI Importance.;D. Partial dependence plots;C;Está en la Tabla 1: Resumen de técnicas de explicabilidad (bloque de “Interpretación de modelos”). (Tabla 1, págs. 34–35).
2;Mod E – P5. ¿Qué técnica genera perturbaciones sobre una imagen para explicar la clasificación…?;A. Integrated gradients;B. XRAI;C. LIME.;D. Grad-CAM;C;En el tema, LIME se recoge como técnica basada en perturbaciones para explicar predicciones (en el resumen de técnicas para imágenes). (Tabla 1, págs. 34–35).
2;Mod E – P6. ¿A qué se refiere la explicabilidad global de un modelo?;A. A la importancia o influencia de una variable en las predicciones.;B. A la capacidad del modelo para explicar sus predicciones a los usuarios;C. A la precisión del modelo en un conjunto de datos de prueba;D. A la complejidad del modelo;A;"El tema lo define explícitamente: global = influencia en todas las predicciones; local = influencia para una observación concreta. (Sección 2.6 Introducción a la explicabilidad, pág. 33)."
2;Mod E – P9. ¿Cuál es la principal característica del ML automatizado (AutoML)?;A. Permite crear modelos sin necesidad de programar ni tener conocimientos avanzados en ciencia de datos.;B. Es una técnica exclusiva de Azure Machine Learning.;C. Únicamente se puede utilizar desde una interfaz gráfica.;D. Garantiza la creación del modelo más preciso posible.;A;El tema lo dice tal cual: AutoML genera modelos automáticamente “sin necesidad de conocer un lenguaje de programación o disponer de conocimientos avanzados…”. (Sección 2.1 Introducción, pág. 3).
2;Mod D - P6 ¿Cuál de las siguientes técnicas de explicabilidad NO está implementada en Vertex AI?;A. SHAP;B. Integrated gradients;C. XRAI;D. Partial dependence plots;D;En el Tema 2 se indica que Vertex AI implementa SHAP, Integrated gradients y XRAI (y explicabilidad basada en ejemplos), por lo que no incluye Partial dependence plots.
2;¿Qué información se debe proporcionar en Google Vertex AI para entrenar un modelo con AutoML?;A. Únicamente un dataset;B. Un dataset y el tipo de modelo;C. Un dataset, tipo de modelo, nombre del modelo y columna objetivo de las predicciones;D. Un dataset, tipo de modelo, nombre de modelo, algoritmo utilizado y variable que se desea predecir;c;AutoML necesita el dataset, el tipo de modelo y el target (columna objetivo) para entrenar.
2;¿Qué es el Model Registry de Google Vertex AI?;A. Un repositorio de modelos pre-entrenados facilitados por Google;B. Un entorno en el que se pueden almacenar los modelos entrenados por el usuario para facilitar el control de versiones;C. Un entorno en el que se pueden almacenar modelos entrenados previamente para control de versiones y facilitar su posterior despliegue;D. Un repositorio de modelos desplegados en diferentes endpoints;c;Es un registro central para almacenar/versionar modelos y facilitar su gobierno y despliegue posterior.
2;Mod D - DESARROLLO: 5) ¿Para qué tipo de datos son más adecuados GCS?;"GCS es más adecuado para datos no estructurados. 
Ejemplos: imagen, vídeo, audio u otros “blobs”. 
Es almacenamiento por objetos, eficiente a gran escala. 
Funciona especialmente bien con datos estáticos (write-once/read-frequently).";;;;A;"Se indica que GCS (almacenamiento por objetos) es recomendable para datos no estructurados como imagen, vídeo y audio; y que rinde mejor con datos estáticos."
3;¿Qué es un entorno (environment) de entrenamiento en Azure Machine Learning?;A. Es una máquina virtual en la que se ejecuta el proceso de entrenamiento.;B. Es un contenedor Docker con el software necesario para las tareas de desarrollo en el proceso de entrenamiento.;C. Es un sinónimo de experimento (experiment).;D. Es un contenedor Docker especializado en el ajuste de hiperparámetros.;b;En efecto, la configuración del entorno incluye las librerías que necesita el código fuente para ejecutar correctamente el proceso de entrenamiento.
3;¿Para qué sirve la utilidad AzCopy de Azure?;A. Es el cliente de línea de comandos de Azure, que sirve para crear, modificar o eliminar un recurso en Azure.;B. Es una utilidad de línea de comandos diseñada para subir datos a Azure.;C. Es una herramienta disponible en el portal de Azure para subir datos a un workspace de Azure Machine Learning.;D. Es una herramienta disponible en el portal de Azure para copiar datos entre cuentas de almacenamiento.;b;AzCopy puede descargarse desde el sitio web de Microsoft para diferentes sistemas operativos, y permite subir datos a Azure desde otros proveedores, como Amazon o Google.
3;¿Cuál es la diferencia entre un dataset y un datastore en Azure Machine Learning?;A. Un dataset es una fuente de datos, mientras que un datastore es una abstracción de los datos reales que están almacenados en un dataset.;A. Un dataset es una fuente de datos, mientras que un datastore es una abstracción de los datos reales que están almacenados en un dataset.;C. Ambos son conceptos equivalentes en Azure Machine Learning.;D. Un dataset es una abstracción de los datos reales, mientras que el datastore son los datos reales.;b;Ambos conceptos permiten abstraerse de los detalles de ubicación y formato de los datos y la fuente que los proporciona, y centrarse en su utilidad para construir modelos predictivos eficaces.
3;¿Qué función cumple un HyperDriveStep en un pipeline de Azure Machine Learning?;A. Permite transferir datos de un datastore a un workspace de Azure Machine Learning.;B. Permite automatizar el ajuste de hiperparámetros.;C. Permite paralelizar la ejecución de procesos de entrenamiento.;D. Sirve para configurar la infraestructura en la que se ejecutarán los procesos de entrenamiento.;b;La posibilidad de automatizar el proceso de ajuste de hiperparámetros agiliza el proceso de creación de modelos, dado que, si tiene que realizarse de forma manual, resulta una actividad tediosa y repetitiva.
3;¿Cuál es la principal ventaja en el uso de pipelines en Azure Machine Learning?;A. Visualmente, queda mucho más claro qué finalidad tiene el modelo que se genera como resultado de la ejecución del pipeline.;B. Permiten reutilizar código fuente asociado a determinadas tareas repetitivas entre experimentos.;"C. No presenta ninguna ventaja; es simplemente el enfoque adoptado en Azure Machine Learning para abordar la creación de modelos. Otros proveedores de nube han adoptado enfoques diferentes igualmente válidos.";D. El hecho de que cada bloque del pipeline se realiza de forma automática, a diferencia de los notebooks, en los que el trabajo es 100 % manual.;b;En el proceso de creación de modelos, el foco debe ponerse en las tareas de mayor valor, fomentando la reutilización de código en todas aquellas que no sufrirán variaciones entre experimentos, como, por ejemplo, la preparación de los datos.
3;¿Qué es Horovod y para qué se utiliza en Azure Machine Learning?;A. Es un lenguaje de programación orientado a redes neuronales.;B. El framework Horovod sirve para implementar paralelismo de datos en redes neuronales.;C. Horovod es un lenguaje de programación que sirve para implementar paralelismo de datos en redes neuronales.;D. Es un framework diseñado para entrenar redes neuronales con GPUs.;b;Desarrollado por Uber, este framework permite agilizar el proceso de entrenamiento mediante el uso de una arquitectura distribuida.
3;¿Para qué sirve el parámetro evaluation_interval en HyperDrive?;A. Indica en qué posiciones del dataset se encuentran los datos de validación.;B. Indica cada cuántas ejecuciones debe evaluarse la política de finalización temprana.;C. Indica cada cuántos minutos debe evaluarse la política de finalización temprana.;D. Indica en qué ejecuciones específicas debe evaluarse la política de finalización temprana.;b;Este parámetro determina en qué momento se debe comparar el rendimiento de los diferentes runs de HyperDrive para, según la política de finalización temprana elegida, puedan cancelarse aquellos que están obteniendo peores resultados.
3;¿En qué se diferencia gradient descent de distributed gradient descent?;A. En el caso de Azure Machine Learning, son términos intercambiables.;B. DGD es un optimizador similar a gradient descent, pero diseñado para funcionar en entornos distribuidos (con múltiples nodos que participan en el proceso de entrenamiento).;C. Gradient descent está optimizado para entornos distribuidos en general, mientras que DGD se especializa en entornos distribuidos con GPUs.;D. DGD es una variante optimizada de gradient descent que se ejecuta más rápidamente, y por tanto permite completar el proceso de entrenamiento en un tiempo inferior.;b;La capacidad de DGD de funcionar en un entorno distribuido es clave para reducir el tiempo de entrenamiento de redes neuronales, que habitualmente requieren grandes volúmenes de datos para proporcionar resultados precisos.
3;¿Para qué sirve la clase azureml.datadrift.DataDriftDetector del SDK?;A. Sirve para corregir el concept drift detectado en los datos.;B. Sirve para detectar concept drift en los datos.;C. Sirve para detectar y corregir el concept drift en los datos.;D. Sirve para detectar datos obsoletos en un dataset.;b;El concept drift se refiere a los cambios que experimentan las relaciones entre los datos, lo que provoca que un modelo entrenado con datos antiguos deje de ser eficaz con las nuevas predicciones.
3;¿Cómo funciona la median stopping policy, en el contexto de la finalización temprana de HyperDrive?;A. Se cancela una ejecución (run) si la mediana de los valores de rendimiento (según la métrica elegida) obtenidos hasta el intervalo actual está por debajo de la mediana de las medias móviles del resto de ejecuciones (runs);B. Se cancela una ejecución (run) si la media móvil de los valores de rendimiento (según la métrica elegida) obtenidos hasta el intervalo actual está por debajo de la mediana de las medias móviles del resto de ejecuciones (runs);C. Se cancela una ejecución (run) si la mediana de los valores de rendimiento (según la métrica elegida) obtenidos hasta el intervalo actual está por debajo del promedio de las medias móviles del resto de ejecuciones (runs).;D. Se cancela una ejecución (run) si la mediana de los valores de rendimiento (según la métrica elegida) obtenidos hasta el intervalo actual está por encima del promedio de las medias móviles del resto de ejecuciones (runs).;b;Esta política utiliza la combinación de la mediana y la media móvil como valor de referencia. Otras alternativas son truncation selection o bandit policy, también disponibles en Azure Machine Learning con HyperDrive.
3;mod e - p7 ¿Qué técnica se utiliza para reducir el tiempo de entrenamiento de un modelo utilizando varios nodos de forma simultánea?;A. Finalización temprana.;B. Optimización bayesiana.;C. Paralelismo de datos.;D. Ajuste de hiperparámetros.;C;Porque el tema define que el paralelismo de datos reduce el tiempo de entrenamiento al usar varios nodos simultáneamente (Tema003, 3.8, p.34).
3;mod e - p8 ¿Qué parámetro de configuración de AutoML controla el nivel de detalle de las trazas del proceso?;A. experiment_timeout_minutes.;B. primary_metric.;C. verbosity.;D. n_cross_validations.;C;Porque el tema lista como parámetro de AutoML el “nivel de detalle aportado en las trazas (logs)” y lo mapea a verbosity (Tema003, 3.7, p.31).
3;mod e - p9 ¿Cuál es la principal característica del machine learning automatizado (AutoML)?;A. Permite crear modelos sin necesidad de programar ni tener conocimientos avanzados en ciencia de datos.;B. Es una técnica exclusiva de Azure Machine Learning.;C. Únicamente se puede utilizar desde una interfaz gráfica.;D. Garantiza la creación del modelo más preciso posible.;A;Porque el tema define AutoML como creación automática de modelos donde no es necesario programar ni tener conocimientos avanzados (Tema003, 3.7, p.31).
3;mod d - p8 ¿Qué estándar de intercambio de mensajes se utiliza habitualmente en Horovod?;A. HTTP.;B. TCP/IP.;C. MPI.;D. No existe ningún estándar para intercambio de mensajes.;C;En el Tema 3 se indica explícitamente que MPI es un estándar de intercambio de mensajes entre nodos y que Horovod lo utiliza para el entrenamiento distribuido (Tema003, p. 36).
3;mod d - p9 ¿Qué framework se utiliza para implementar paralelismo de datos en redes neuronales?;A. HyperDrive.;B. AutoML.;C. Horovod.;D. DataDriftDetector.;C;El Tema 3 dice que Horovod es una alternativa para implementar paralelismo de datos en redes neuronales en Azure ML (Tema003, p. 34).
3;¿Cuál es la relación entre experimentos y modelos registrados en Azure Machine Learning?;A. Cada experimento tiene asociado un modelo registrado;B. Cada modelo registrado es el resultado de un experimento;C. Múltiples experimentos se agrupan en un modelo registrado;D. Múltiples modelos registrados se agrupan en un experimento;b;Un modelo registrado normalmente proviene de una ejecución (run) dentro de un experimento.
3;¿Es posible ingestar datos desde un pipeline creado en Azure Machine Learning Designer?;A. No, esa etapa debe completarse previamente a la creación del pipeline, puesto que cada pipeline está vinculado exclusivamente a un dataset;B. Sí es posible, pero debe realizarse a través de código fuente en Python;C. No, no es posible porque Designer sólo permite trabajar con datos de ejemplos proporcionados por el propio entorno;D. Sí es posible, a través del step correspondiente;d;Designer permite incluir pasos/componentes para cargar/ingestar datos dentro del pipeline.
3;"Mod D - DESARROLLO: 4) ¿Cuál es la finalidad del siguiente código?

from azureml.core.compute import ComputeTarget, AmlCompute
nombre
cluster = ""cluster1""
tipo__vm = ""STANDARD_NC6""
max_nodes = 2
_
(Responder en 4 líneas)";"Define la configuración para crear/provisionar un clúster de cómputo en Azure ML.
El clúster se llamaría ""cluster1"" y usaría VM GPU STANDARD_NC6. 
Se limita el escalado a máximo 2 nodos (max_nodes = 2). 
Se usa para ejecutar entrenamientos (p.ej., deep learning) en infraestructura elástica.";;;;A;Hay un ejemplo de creación de infraestructura GPU en Azure ML usando AmlCompute.provisioning_configuration(...) y ComputeTarget.create(...) con STANDARD_NC6 y límites de nodos.
4;¿Para qué sirve la herramienta JumpStart de SageMaker?;A. JumpStart es la infraestructura de computación gestionada por Amazon, que podemos utilizar para ejecutar procesos de entrenamiento.;B. JumpStart es un catálogo de soluciones y modelos que resuelven los casos de uso más habituales de cada sector.;C. JumpStart es una colección de datasets proporcionados por Amazon para realizar pruebas de algoritmos y establecer benchmarks.;D. JumpStart es la solución de Amazon que permite detectar sesgos e importancia de características en una predicción.;b;Esta herramienta de SageMaker permite agilizar la implementación de casos de uso que aparecen recurrentemente en las organizaciones.
4;¿Qué datos se pueden almacenar en cada trial de un experimento?;A. Solo la información relativa al experimento, es decir, su nombre y su descripción.;B. Datos empleados, transformaciones aplicadas, valores de hiperparámetros, estimador elegido, métricas de rendimiento y gráficas generadas.;C. Datos empleados, transformaciones aplicadas y valores de hiperparámetros.;D. Datos empleados, transformaciones aplicadas, valores de hiperparámetros, estimador elegido y métricas de rendimiento.;b;Todos los elementos citados pueden almacenarse en las trazas de un trial, y sirven para poder comparar los resultados obtenidos por diferentes trials.
4;¿Qué efecto tiene la llamada sagemaker.Session()?;A. Devuelve información acerca de la sesión SageMaker en curso.;B. Crea una sesión de SageMaker, a través de la cual se utilizan todas las funcionalidades que ofrece el SDK.;C. No tiene efecto, puesto que el notebook ya dispone de una sesión que puede utilizar para realizar llamadas al SDK.;D. Crea una sesión de SageMaker, que posteriormente tenemos que activar con la llamada enable() para acceder a las funcionalidades del SDK. ;b;Esta llamada forma parte del proceso de inicialización en un notebook Jupyter, en la que se obtienen otras características como el rol de ejecución o la región.
4;¿Para qué puede utilizarse en Data Wrangler un scatter plot que enfrenta los valores de dos características?;A. No es posible representar los valores de dos características en un scatter plot.;B. Para detectar correlación entre las características.;C. Para determinar la frecuencia de cada valor o rango de valores de cada una de las características.;D. Data Wrangler no ofrece la posibilidad de visualizar un scatter plot.;b;Esta técnica permite detectar la correlación entre características. Si los puntos generados se aproximan a una línea recta, la correlación es elevada.
4;¿Qué es el modelado rápido de Data Wrangler?;A. Un ejercicio de construcción de un modelo con el perfil de hardware más potente del que dispone Amazon.;B. Un ejercicio de construcción de un modelo a partir de un fragmento de los datos para anticipar la viabilidad de un modelo completo.;C. Un ejercicio de construcción de un modelo con GPUs, que son el hardware óptimo para acelerar el proceso de entrenamiento.;D. Un ejercicio de construcción de un modelo con un algoritmo trivial, lo que permite obtener resultados aproximados rápidamente.;b;De esta forma, podemos comprobar las posibilidades de construir un modelo eficaz, invirtiendo tiempo y esfuerzo adicional en el proceso.
4;¿Cuáles son los tres componentes de un Feature Store?;A. Experimentos, definiciones de características y datos ingestados.;B. Colección de fuentes de datos de las que extrae características y datos, definiciones de características y datos ingestados.;C. Colección de fuentes de datos de las que extrae características y datos, definiciones de características e hiperparámetros.;D. Colección de fuentes de datos de las que extrae características y datos, modelos e hiperparámetros.;b;Estos tres componentes interactúan para centralizar en un repositorio las características y datos que necesitan los científicos de datos, de forma independiente a los equipos de ingeniería de datos.
4;¿Qué implicaciones positivas tiene la centralización de características en un único repositorio?;A. Permite que se utilicen las mismas características en el entrenamiento y en la inferencia.;B. Evita que varios científicos de datos construyan las mismas características por separado, y permite que se utilicen las mismas características en el entrenamiento y en la inferencia.;C. Evita que varios científicos de datos construyan las mismas características por separado.;D. Evita que cada científico de datos construya su propio feature store.;b;Las transformaciones de datos para generar características es una tarea que consume mucho tiempo. Por ello, la disponibilidad de un feature store permite agilizar estas tareas y concentrarse en la labor de creación de modelos eficaces.
4;¿Para qué sirve la llamada sagemaker.image_uris.retrieve()?;A. Retorna un puntero a un contenedor que incluye los paquetes de software correspondientes a un framework, como TensorFlow o PyTorch.;B. Retorna un puntero a una imagen que contiene los paquetes de software correspondientes a un framework, como TensorFlow o PyTorch.;C. Retorna un puntero a una imagen que contiene un sistema operativo optimizado para la creación de modelos.;D. Retorna el listado de imágenes disponibles para encapsular procesos de preparación de datos o entrenamiento.;b;Esta imagen puede ser utilizada para construir un contenedor encargado de ejecutar un proceso de entrenamiento en la infraestructura de computación elegida.
4;¿Qué ventaja tiene incorporar los notebooks a un repositorio Git?;A. Que se dispone de un backup en caso de que se borren accidentalmente las copias originales.;B. La posibilidad de identificar fácilmente los cambios que se han realizado de una versión a otra.;C. No presenta ninguna ventaja, simplemente es una práctica habitual en el ámbito DevOps.;D. La posibilidad de identificar fácilmente las diferencias entre dos notebooks similares.;b;Detectar cambios entre versiones es clave para proporcionar trazabilidad en los modelos, es decir, ser capaces de explicar cómo se ha construido un modelo que actualmente está en producción.
4;¿En qué consiste el sesgo de modelos?;A. En que un modelo genera predicciones erróneas, porque no disponía de suficientes datos durante el proceso de entrenamiento.;B. En que un modelo genera una predicción favorable a un grupo o desfavorable o errónea a otro grupo, por la simple pertenencia a estos grupos.;C. En que un modelo genera una predicción favorable a un grupo o desfavorable o errónea a otro grupo, basándose en múltiples criterios objetivos.;D. El sesgo solo existe en los datos, no en los modelos.;b;Este tipo de sesgo perjudica a determinados grupos infrarrepresentados, porque evita que el modelo evalúe de forma equitativa todas las características a su alcance para dirigir la predicción hacia un valor u otro.
4;mod e - p10 ¿Cuáles son los beneficios de utilizar un almacén de características?;A. Independencia de las características y los datos de la fuente.;B. Centralización de las características en un único repositorio.;C. Trazabilidad y auditoría.;D. Todas las anteriores;D;El tema enumera como beneficios del feature store independencia, centralización y trazabilidad/auditoría, así que aplican A+B+C.
4;mod e - p11 ¿Qué permite un almacén de características en SageMaker? ;A. Almacenar características y datos en un único repositorio alimentado por múltiples fuentes de datos independientes;B. Entrenar modelos de aprendizaje automático utilizando algoritmos preconstruidos.;C. Desplegar modelos entrenados en endpoints para la inferencia en tiempo real.;D. Supervisar los modelos en producción para detectar la degradación del rendimiento.;A;El tema define el feature store justo así: repositorio único de características y datos, alimentado por múltiples fuentes.
4;mod e - p12 ¿Cuál de las siguientes NO es una función de transformación de datos común disponible en Data Wrangler?;A. Codificación de características categóricas;B. Gestión de datos ausentes;C. Realización de un análisis de componentes principales (PCA);D. Eliminación de valores atípicos;C;En el listado de “funciones más comunes” del tema aparecen codificación, imputación de ausentes y eliminación de outliers, pero no PCA.
4;mod d - p11 ¿Cómo se gestiona el almacenamiento de datos offline en SageMaker Feature Store?;A. En una base de datos relacional gestionada por AWS.;B. En una base de datos NoSQL como Amazon DynamoDB.;C. En un bucket de S3 con un catálogo de datos de AWS Glue y expuesto a través de una API SQL en Amazon Athena.;D. El almacenamiento de datos offline no es compatible con SageMaker Feature Store.;C;El tema indica que el modo offline guarda en S3, cataloga con AWS Glue Catalog y se consulta vía SQL en Athena.
4;mod d - p12 ¿Cómo se puede automatizar la creación de un grupo de características en SageMaker?;A. Escribiendo un script Python personalizado utilizando el SDK de SageMaker.;B. Incorporando un paso de exportación en Data Wrangler y seleccionando Feature Store como opción de exportación.;"C. Cargando manualmente las definiciones de las características y los datos en el
almacén de características.";D. La creación de grupos de características no se puede automatizar en SageMaker.;B;El tema explica que puede automatizarse desde Data Wrangler con Export step → Feature Store y ejecutar el notebook resultante en SageMaker Processing.
4;¿En qué consiste la funcionalidad de Modelado Rápido (Quick Model) en AWS SageMaker?;A. Permite anticipar el grado de sesgo en el modelo;B. Permite anticipar la precisión del modelo, construyendo un modelo Random Forest;C. Permite reducir el tiempo de entrenamiento del modelo definitivo;D. Esta funcionalidad no está presente en AWS SageMaker;b;Entrena un modelo rápido para estimar rendimiento antes de invertir en el entrenamiento “final”.
5;¿Cuáles son los beneficios para la IA generativa de una arquitectura nativa de nube?;A. Clasificación de textos, chatbots, generación de imágenes y traducción.;B. Capacidad de computación, agilidad, innovación e interoperabilidad.;C. Menor coste de adquisición de infraestructura y más potencia de computación.;D. Capacidad de computación, agilidad e innovación.;B;Estas cuatro características son las que han permitido expandir el uso de la IA generativa al ritmo que hemos visto en los últimos dos años. De no haber estado suficientemente desarrollada la computación en la nube, la IA generativa habría tenido mucho menos impacto.
5;¿Cuál es la diferencia entre los modelos de OpenAI Codex y DALL-E?;A. El primero se utiliza para generar imágenes a partir de una descripción, el segundo para generar código fuente a partir de lenguaje natural.;B. El primero se utiliza para generar código fuente a partir de lenguaje natural, el segundo para generar imágenes a partir de una descripción.;C. Ambos se utilizan para implementar chatbots avanzados.;D. Son diferentes versiones del mismo modelo que procesa lenguaje natural.;B;Las capacidades de generación de código a partir de descripciones facilitan y agilizan el trabajo de los desarrolladores, mientras que DALL-E ayuda a los profesionales del diseño creativo y la publicidad.
5;¿Qué es un embedding y qué aplicaciones tiene?;A. Es una representación matemática de una palabra o texto. Se utiliza para agilizar las respuestas de un buscador, dado que es más rápido procesar números que texto.;B. Es una representación matemática de una palabra o texto. Se utiliza para detectar textos similares, búsqueda de información sobre un tema o generación de código fuente a partir de lenguaje natural.;C. Es el valor numérico asociado al significado de una palabra o texto. Se utiliza para detectar textos similares, búsqueda de información sobre un tema o generación de código fuente a partir de lenguaje natural.;D. Es una forma de codificación de palabras y texto que permite almacenar información sobre un tema en menos espacio que su equivalente en texto.;B;La representación matemática posibilita la comparación de palabras o textos mediante fórmulas para medir su similitud. A partir del valor numérico de similitud, es sencillo determinar si dos palabras o textos tienen una semántica coincidente.
5;¿Para qué se utiliza un Playground en Azure OpenAI Studio?;A. Es el entorno utilizado por usuarios avanzados para desarrollar soluciones de IA generativa en Azure.;B. Para realizar experimentos y pruebas en el proceso de incorporar IA generativa a una aplicación, a través de una interfaz gráfica.;C. Es un simulador de IA generativa que sirve para aprender los conceptos esenciales, pero no permite construir soluciones reales.;D. Para realizar experimentos y pruebas en el proceso de incorporar IA generativa a una aplicación, mediante código fuente.;B;Este proceso de experimentación es muy ágil por el uso de una interfaz gráfica en lugar de código fuente, lo que permite desarrollar pruebas de concepto en plazos muy cortos.
5;¿Qué significado tiene el valor de temperatura en un LLM?;A. Representa el número de tókenes utilizado en la respuesta.;B. Representa el grado de determinismo o creatividad en la respuesta a un prompt.;C. Representa en qué medida aparece en la respuesta contenido violento o inadecuado.;D. Representa el tiempo invertido por el chatbot en generar la respuesta.;B;Dependiendo del caso de uso, la creatividad o el determinismo pueden ser requisitos. Por ejemplo, en relación con los procedimientos internos de una organización, es preferible que las respuestas sean certeras y deterministas.
5;¿Qué procedimiento se debe seguir para desplegar en una aplicación web un chatbot basado en IA generativa construido en un playground?;A. Escribir un template de despliegue basado en Azure Resource Manager, y utilizar un agente de despliegue para alojarlo en una URL.;B. Pulsar el botón «Deploy to» en Azure OpenAI Studio, y proporcionar un nombre y perfil de hardware para la aplicación.;C. El procedimiento de despliegue implica utilizar el SDK de Python para dar las órdenes de despliegue a través de la API de Azure.;D. Pulsar el botón «Deploy to» en Azure OpenAI Studio y especificar un JSON con las características del despliegue.;B;Esta facilidad para desplegar aplicaciones web con IA generativa potencia el ritmo y alcance de adopción en las organizaciones.
5;¿En qué consiste el fine-tuning de un modelo?;A. El proceso de fine-tuning se utiliza para incorporar bases de conocimiento nuevas sobre temáticas especializadas, codificando reglas que determinan en qué casos se debe utilizar el nuevo contenido.;B. El proceso de fine-tuning se utiliza para incorporar bases de conocimiento nuevas sobre temáticas especializadas, realizando un reentrenamiento de uno de los modelos proporcionados por OpenAI.;C. El proceso de fine-tuning se utiliza para corregir respuestas inapropiadas a determinados prompts.;D. El proceso de fine-tuning se utiliza para reducir la complejidad de las respuestas y las posibles alucinaciones del chatbot.;B;De esta forma es posible personalizar cualquiera de los modelos preentrenados para adaptarse a escenarios no contemplados en el entrenamiento original o aquellos que se basan en información privada.
5;¿Cuál de las siguientes es una característica de LangChain?;A. La posibilidad de actuar como vector store a partir de una base de datos PostgreSQL.;B. La disponibilidad de una interfaz común para trabajar con cualquiera de los principales LLMs.;C. La posibilidad de escribir código fuente en Python, C#, Java y GoLang.;D. La disponibilidad de un entorno de dashboarding para medir la evolución de la precisión en las respuestas de los modelos LLM utilizados.;B;Dada la amplia oferta de LLMs disponibles, la posibilidad de trabajar con un único entorno para acceder a todos ellos es realmente una ventaja diferencial.
5;¿A qué se refiere el término data augmented generation (DAG)?;A. Se refiere a los mecanismos que permiten realizar actividades de orquestación entre diferentes LLMs.;B. Se refiere a los mecanismos que permiten incorporar información de fuentes externas en la respuesta.;C. Se refiere a los mecanismos que permiten generar embeddings para almacenarlos en un vector store.;D. Se refiere a la posibilidad de mejorar un modelo, incorporando nuevos ejemplos.;B;El DAG solventa una de las limitaciones de los LLMs, que es alcance temporal de su proceso de entrenamiento. De esta forma, es posible incorporar información muy reciente que no fue contemplada en el entrenamiento original.
5;¿En qué se diferencia un agent de un chain de LangChain?;A. No existe ninguna diferencia, son términos intercambiables.;B. Los agentes son capaces de ejecutar diferentes secuencias de acciones en función de los resultados obtenidos en acciones previas, mientras que las chains ejecutan una secuencia estática de acciones.;C. Los agentes ejecutan una secuencia estática de acciones, mientras que las chains son capaces de ejecutar diferentes secuencias de acciones en función de los resultados obtenidos en acciones previas.;D. Una chain es una versión especializada de un agente para un determinado LLM.;B;Los agentes incorporan una capa de razonamiento que permite determinar el mejor curso de acción de forma dinámica, lo que permite reaccionar mejor a cambios en las fuentes de datos y proporcionar respuestas más precisas.
5;mod e - p13 ¿Cómo se define el template de un prompt en LangChain?;A. Utilizando un lenguaje de marcado específico de LangChain.;B. Escribiendo una función en Python que genera el texto del prompt.;C. Utilizando una cadena de texto con variables que se rellenan con los valores específicos del prompt.;D. Importando un archivo JSON que contiene la estructura del prompt.;C;"Porque los ejemplos definen el prompt como string con placeholders (p. ej. ""Describe a perfect day in {city}?"" o """"""Question: {question}"""""") y se construye con PromptTemplate (Tema 5, Ideas clave, LangChain / Ejercicios, p. 38–39 y p. 51)."
5;mod e - p14 ¿Para qué se utiliza el método openai.Deployment.list() en el SDK de OpenAI para Python?;A. Para crear un nuevo deployment para un modelo específico.;B. Para enviar un prompt al modelo y obtener una respuesta.;C. Para obtener una lista de todos los deployments disponibles.;D. Para eliminar un deployment que ya no se necesita.;C;Porque el tema indica que para recuperar un deployment operativo primero se listan todos con result = openai.Deployment.list() y luego se filtra por status/modelo (Tema 5, Ideas clave, Cuaderno de ejercicios, p. 49–50).
5;mod e - p15 ¿Cuál es la función del parámetro seed en la llamada a client.chat.completions.create() en el SDK de OpenAI para Python?;A. Definir el grado de determinismo o creatividad en la respuesta a un prompt.;B. Controlar la generación aleatoria para obtener respuestas reproducibles con el mismo prompt.;"C. Especificar el número máximo de tokens que puede contener la respuesta del
modelo.";"D. Incluir un número determinado de mensajes anteriores como contexto en la
generación de la respuesta.";B;Porque el tema explica “concepto de seed … y requisito de reproducible output” y el ejemplo fija seed=42 para repetir salidas iguales/similares (Tema 5, Ideas clave, Cuaderno de ejercicios, p. 47–48).
5;mod c - p17 ChatGPT no es sólo un chatbot, sino que puede entrenarse para realizar tareas propias de ML, como la clasificación de un texto:;A. Falso;B. VERDADERO;;;B;Porque el tema describe que con “Completions” se pueden hacer tareas como clasificar un texto y que se puede guiar el comportamiento con ejemplos (few-shot), lo que equivale a “entrenarlo” a nivel de prompt (Tema 5, Ideas clave, Completions, p. 16).
5;mod d - p14 ¿Cuál es la función del SDK de Bot Framework en el desarrollo de chatbots?;A. Proporcionar una interfaz gráfica para diseñar y configurar el chatbot.;B. Alojar el chatbot en la nube y conectarlo a diferentes canales de comunicación.;C. Probar el chatbot antes de su despliegue en un entorno real.;D. Proporcionar herramientas y bibliotecas para diseñar e implementar bots a partir de código fuente en C#, Python, Java o Javascript.;D;Porque el tema define el SDK de Bot Framework como el componente que “permite diseñar e implementar bots a partir de código fuente en C#, Python, Java o Javascript” (Tema 5, Bot Framework, pág. 42).
5;mod d - p15 ¿Qué información se puede obtener de los logprobs en la respuesta de un modelo de OpenAI?;A. El tiempo que ha tardado el modelo en generar la respuesta.;B. El número de tokens que se han utilizado en la respuesta.;C. El grado de similitud entre la respuesta y el prompt.;D. La probabilidad de los tokens de la secuencia dado el contexto, indicando la confianza del modelo en la respuesta.;D;Porque el tema explica que los logprobs son “la probabilidad de los tókenes… dado el contexto” y que “son una indicación de la confianza del modelo” (Tema 5, Cuaderno de ejercicios, ejercicio de logprobs, pág. 51).
5;¿Para qué sirve un Deployment en Azure OpenAI Services?;A. Proporciona acceso a los modelos pre-entrenados de OpenAI, y su creación es un requisito imprescindible para utilizarlos;B. Proporciona acceso a los modelos pre-entrenados de OpenAI, pero también pueden ser utilizados en ausencia de un deployment;C. Permite desplegar un chatbot en un endpoint;D. Sirve únicamente para facturación y no afecta al acceso a modelos;a;En Azure OpenAI se invoca un deployment (nombre+modelo/config), no el modelo “directamente”.
6;Proporcionar contexto a ChatGPT durante la escritura de un prompt permite:;A. Obtener una respuesta más rápidamente.;B. Obtener una respuesta más precisa.;C. Obtener una respuesta más completa.;D. Es indiferente, ChatGPT no considera la información de contexto proporcionada por el usuario.;B;En efecto, la incorporación de un contexto a la pregunta es una técnica de prompting que permite alcanzar una mayor precisión en los resultados. Esta precisión es especialmente necesaria cuando la respuesta es tratada por una aplicación.
6;ChatGPT puede utilizarse como asistente para la creación de una aplicación de software. En particular, puede ayudarnos con:;A. Solamente el esbozo de una arquitectura de alto nivel.;B. La arquitectura y la implementación del código fuente.;C. Solo con la implementación del código fuente de una función concreta.;"D. ChatGPT no puede utilizarse de este modo; para este propósito, deben utilizarse herramientas como GitHub Copilot.";B;ChatGPT puede generar una arquitectura de alto nivel que esboce los pasos a seguir para implementar la funcionalidad deseada, pero también puede generar el código fuente asociado a cada una de las funciones de esta arquitectura.
6;ChatGPT no es solo un chatbot, sino que puede entrenarse para realizar tareas propias de algoritmos de machine learning, como la asignación de una categoría a un texto (clasificación):;A. Falso.;B. Verdadero.;;;B;ChatGPT puede utilizar ejemplos proporcionados en el prompt o mediante otros métodos para determinar cómo clasificar instancias de texto. Por tanto, efectivamente puede realizar una tarea propia de un algoritmo de machine learning.
6;El conteo de número de tókenes es un aspecto clave para controlar el consumo. Esta tarea puede realizarse con la librería:;A. Midjourney.;B. Tiktoken.;C. ChatGPT.;D. OpenAICounter.;B;Tiktoken es un tokenizador diagram que se utiliza con los modelos de OpenAI para contar el número de tókenes asociados a un prompt y su respuesta, lo que permite mantener el consumo por debajo de los límites que establece la API de OpenAI.
6;LangChain proporciona una clase para interactuar con las capacidades de chatbot de OpenAI. El nombre de esta clase es:;A. LLMChain.;B. ChatOpenAI.;C. PromptTemplate.;D. OpenAIChatModel.;B;Esta clase se inicializa con el modelo preentrenado de OpenAI que se desea utilizar y el nivel de temperatura asociado a las respuestas.
6;¿En qué consiste el streaming de respuestas tras la recepción y procesamiento de un prompt en un LLM?;A. En imprimir varias respuestas simultáneamente.;B. En imprimir la salida de una respuesta a medida que se va generando, en lugar de esperar a que se genere en su totalidad para imprimirla.;C. En imprimir la respuesta a varios usuarios conectados a la misma interfaz.;D. En imprimir respuestas relacionadas de forma paralela.;B;El uso de streaming permite reducir la percepción de espera del usuario, porque el tiempo que invierte en leer la primera parte de la respuesta se utiliza para generar el resto de contenido.
6;¿Qué función cumplen las plantillas en LangChain?;A. Permiten ejecutar una secuencia de acciones predeterminada.;B. Permite reutilizar y simplificar el código que accede a los LLMs a través de un prompt parametrizable.;C. Permiten ejecutar una secuencia de acciones de forma dinámica, es decir, considerando la salida de las acciones previas.;D. Permite convertir a embeddings el prompt para facilitar su reutilización.;B;En efecto, una plantilla o template en LangChain es un prompt que puede configurarse a través de parámetros. Esto permite generar de forma sencilla múltiples prompts que comparten una estructura.
6;¿Para qué se utiliza la librería Pydantic en LangChain?;A. Para implementar agentes basados en tools.;B. Para extraer datos estructurados a partir de un schema y un texto en lenguaje natural.;C. Pydantic no se utiliza con LangChain, es una librería que sirve para validación de datos en otros entornos, como TensorFlow.;D. Para extraer datos no estructurados a partir de un texto en lenguaje natural.;B;Pydantic es una pieza clave de la integración de IA conversacional en aplicaciones. Permite transformar datos que entiende un ser humano (lenguaje natural) en datos que un software es capaz de tratar (estructurados).
6;FAISS y Pinecone son dos alternativas para implementar vector stores, ¿cuál es la diferencia de enfoque entre ambos?;A. Pinecone es una librería open-source que puede ejecutarse en cualquier PC, mientras que FAISS es un servicio gestionado en cloud.;B. FAISS es una librería open-source que puede ejecutarse en cualquier PC, mientras que Pinecone es un servicio gestionado en cloud.;C. FAISS proporciona un enfoque holístico, es decir, integrar muchas funcionalidades que no están presentes en Pinecone.;D. Pinecone tiene un rendimiento muy superior al de FAISS, independiente del entorno de computación.;B;Pinecone es una alternativa óptima si el objetivo es disponer de un vector store como servicio, es decir, evitar el despliegue y mantenimiento de infraestructura propias para disponer de esta capacidad.
6;¿En qué casos debe utilizarse ReAct frente a OpenAI functions?;A. Cuando el caso de uso que estamos considerando es sencillo y solamente implica extracción de datos y consultas a buscadores.;B. Cuando el número de herramientas necesarias es elevado y se requiere un análisis detallado de las acciones anteriores y sus resultados.;C. En todos los casos, puesto que ReAct es un framework con capacidades muy superiores a las de las funciones de OpenAI.;D. En todos los casos, puesto que ReAct es mucho más sencillo de aprender e implementar en LangChain que las funciones OpenAI.;B;ReAct presenta una mayor versatilidad en la definición de escenarios complejos con dependencias fuertes entre las acciones que debe realizar el agente. Por tanto, debemos utilizar OpenAI functions solo en casos sencillos.
6;Mod A (13). ¿Cuál es la diferencia principal entre un agente y una chain en LangChain?;A. No existe ninguna diferencia, son términos intercambiables.;"B. Los chains siguen una secuencia fija; los agentes deciden el siguiente paso según resultados previos.";"C. Los agentes ejecutan una secuencia estática de acciones, mientras que las chains
son capaces de ejecutar diferentes secuencias de acciones en función de los
resultados obtenidos en acciones previas.";D. Una chain es una versión especializada de un agente para un determinado LLM.;B;Un agente “ejecuta acciones, observa el resultado y decide… la siguiente acción”, mientras que un pipeline/chain es una secuencia definida.
6;Mod A (14). ¿Cuál es el propósito de implementar Data Augmented Generation (DAG) en LangChain?;A. Incorporar fuentes externas (p.ej., documentos/vector stores) para “aumentar” la generación con contexto.;"B. Se refiere a los mecanismos que permiten incorporar información de fuentes externas
en la respuesta.";"C. Se refiere a los mecanismos que permiten generar embeddings para almacenarlos
en un Vector Store.";D. Se refiere a la posibilidad de mejorar un modelo incorporando nuevos ejemplos.;A;El enfoque tipo RAG busca documentos similares y los inyecta como contexto en el prompt (eso es “augmentar” con datos).
6;Mod A (15). ¿Cuál es la principal característica de LangChain?;"A. La posibilidad de actuar como Vector Store a partir de una base de datos Post-
greSQL.";B. Plataforma open-source que ofrece interfaz común en Python para LLMs y utilidades (vector stores, DAG, agentes, memorias…).;C. La posibilidad de escribir código fuente en Python, C#, Java y GoLang.;"D. La disponibilidad de un entorno de dashboarding para medir la evolución de la
precisión en las respuestas de los modelos LLM utilizados.";B;El tema define LangChain como orquestador con interfaz común en Python y “herramientas para potenciar resultados” (vector stores, DAG, agentes…).
6;Mod B (13). ¿En qué consiste el fine-tuning de un modelo?;"A. El proceso de fine-tuning se utiliza para incorporar bases de conocimiento nuevas
sobre temáticas especializadas, codificando reglas que determinan en qué casos se
debe utilizar el nuevo contenido.";B. Reentrenar el modelo para que incorpore nuevos datos/conocimiento de una temática.;"C. El proceso de fine-tuning se utiliza para corregir respuestas inapropiadas a
determinados prompts.";"D. El proceso de fine-tuning se utiliza para reducir la complejidad de las respuestas y las
posibles alucinaciones del chatbot.";B;El tema dice que a veces hay que hacer fine-tuning “para que adquiera una nueva base de conocimiento” aportando datos del dominio.
6;Mod B (15). ¿Qué representa el parámetro temperature en un modelo de OpenAI?;A. Representa el número de tokens utilizado en la respuesta.;B. El grado de determinismo vs creatividad de la respuesta.;C. Representa en qué medida aparece en la respuesta contenido violento o inadecuado.;D. Representa el tiempo invertido por el chatbot en generar la respuesta.;B;El tema indica literalmente que la temperatura influye en el “grado de determinismo o creatividad” de la respuesta.
6;Mod C (14). ¿Qué es un embedding?;"A. Es una representación matemática de una palabra o texto. Se utiliza para agilizar las
respuestas de un buscador, dado que es más rápido procesar números que texto.";B. Una representación matemática/numérica de una palabra o texto para comparar similitud y buscar información relacionada.;"C. Es el valor numérico asociado al significado de una palabra o texto. Se utiliza para
detectar textos similares, búsqueda de información sobre un tema o generación de
código fuente a partir de lenguaje natural.";"D. Es una forma de codificación de palabras y texto que permite almacenar información
sobre un tema en menos espacio que su equivalente en texto.";B;Se define que un vector store guarda la “representación numérica (embeddings) de palabras o textos” para búsquedas/detectar similitudes.
6;Mod E (16). ¿Cuál es el nombre de la interfaz web que incorpora extensiones de usuario para Stable Diffusion?;A. DreamStudio;B. AUTOMATIC1111;C. Lexica.art;D. Hugging Face;B;El tema la describe como “interfaz web” que “incorpora extensiones… y ofrece funcionalidades” adicionales.
6;Mod E (17). ¿Qué parámetro… se utiliza para determinar la influencia del prompt en la generación de la imagen?;A. num_inference_steps;B. guidance_scale;C. generator;D. torch_dtype;B;El propio texto indica: “El parámetro guidance_scale se utiliza para determinar la influencia del prompt”.
6;Mod E (18). ¿Qué comando… se utiliza para instalar las dependencias necesarias para usar Stable Diffusion XL con Python?;A. conda install;B. pip install;C. git clone;D. wget;B;En el apartado “Python SDK” se muestran explícitamente los comandos pip install de dependencias.
6;Mod D (17) ¿Cuál es el nombre del modelo que se utiliza para generar embeddings?;A. gpt-3.5-turbo;B. sentence-transformers/all-MiniLM-l6-v2;C. CompVis/stable-diffusion-v1-4;;B;En el cuaderno (FAISS) se indica explícitamente usar el modelo preentrenado sentence-transformers/all-MiniLM-l6-v2 para generar embeddings.
6;Mod D (18) ¿Qué librería se utiliza para cargar un dataset desde HuggingFace?;A. Pandas;B. HuggingFaceDatasetLoader;C. Scikit-learn;D. NumPy;B;En el ejercicio se usa la clase HuggingFaceDatasetLoader para cargar el dataset databricks/databricks-dolly-15k.
6;¿Qué es un diálogo en Azure Bot Framework?;A. Un mecanismo para desplegar el bot en producción;B. Un componente que define el flujo conversacional y cómo reacciona el bot a entradas del usuario;C. Un conector para integrar bases de datos;D. Un sistema de monitorización del bot;b;Un diálogo modela una “funcionalidad” del bot y define cómo responde ante peticiones del usuario.
6;¿Cómo se implementa el concepto de memoria en Azure Bot Framework?;A. Mediante variables globales compartidas entre todos los usuarios;B. A través de propiedades (properties) con nombre, alcance y valor;C. Guardando siempre el historial completo en un único fichero local;D. No existe el concepto de memoria en Azure Bot Framework;b;La memoria se implementa mediante properties con alcance (turn/user/conversation) y valor persistible.
6;"Mod D - DESARROLLO:  3) ¿Qué tipo de mensajes se generará… creativos o deterministas?

from langchain_openai.chat_models import ChatOpenAI
from langchain.schema import AIMessage, HumanMessage, SystemMessage
chat = ChatOpenAI(temperature=0.0)
(Responder en 4 líneas)";"Generará mensajes deterministas (poca variabilidad). 
Porque temperature=0.0 reduce la creatividad y aumenta el determinismo. 
Con la misma entrada, tenderá a dar salidas muy consistentes. 
Ideal si buscas respuestas reproducibles en un chatbot. ";;;;A;"El temario explica que la temperatura influye en el determinismo o creatividad; con temperature=0.0 se maximiza el comportamiento determinista."
7;En la terminología de Azure Bot Framework, ¿qué es un diálogo?;A. Un diálogo es el componente visual a través del cual se registran las conversaciones entre el chatbot y el usuario.;B. Un diálogo representa una funcionalidad del bot, y define cómo reaccionará a las peticiones del usuario.;C. Un diálogo se refiere al conjunto de mensajes que intercambian el usuario y el chatbot.;D. Un diálogo es un conjunto de respuestas posibles del chatbot a la petición de un usuario.;B;El concepto de diálogo permite encapsular diferentes funcionalidades para que el diseño del chatbot sea modular.
7;¿Para qué sirve un recognizer en Azure Bot Framework?;A. AAA.;B. Un recognizer detecta el significado de la petición del usuario (intent) y extrae sus principales entidades (entities).;C. Un recognizer es llamado cuando sucede algún evento relevante en la conversación.;D. Un recognizer implementa acciones de respuesta a partir de la activación de un trigger.;B;La detección del significado es un proceso clave para poder generar una respuesta válida y ajustada a los condicionantes que expresa el usuario.
7;¿Cómo se realiza la implementación del concepto de memoria en un chatbot creado en Azure Bot Framework?;A. La memoria se implementa a través de variables y constantes, que tienen un nombre y un valor.;B. La memoria se implementa a través de propiedades (properties), que tienen un nombre, un alcance y un valor.;C. La memoria se implementa a través de propiedades (properties), que tienen un nombre y un valor.;D. La memoria se implementa a través de variables y constantes, que tienen un nombre, un alcance y un valor.;B;Las propiedades pueden utilizarse posteriormente para recordar los aspectos clave de los mensajes intercambiados con el usuario hasta el momento.
7;¿Qué es y para qué sirve el Adaptive Runtime?;A. Es el entorno de ejecución en el que se hospedan los chatbots.;B. Es el entorno de ejecución que debe incorporarse como dependencia a un proyecto de chatbot para acceder a la SDK de Bot Framework.;C. Es el entorno de ejecución que debe incorporarse como dependencia a un proyecto de chatbot para acceder a la SDK de Microsoft Copilot Studio.;D. Es el entorno a través del cual se puede desplegar un chatbot.;B;El SDK de Bot Framework proporciona todas las funcionalidades disponibles a través del canvas de Composer y otras más avanzadas que requieren de programación explícita con código fuente en C# o Javascript.
7;¿Para qué se utiliza un sitio web de fallback en Microsoft Copilot Studio?;A. Es la URL a la que accede el copilot cuando se produce un error durante el intercambio de mensajes en la conversación con el usuario.;B. Es la URL a la que accede el copilot cuando desconoce la respuesta a una petición del usuario para buscar información relevante que permita dar con dicha respuesta.;C. Es la URL a partir de la que el copilot genera todas sus respuestas, lo que evita tener que entrenar un modelo previamente.;D. Es la URL a través de la cual puede utilizarse el copilot.;B;Esta funcionalidad es clave para extender la capacidad del bot de generar respuestas útiles a peticiones que quizá no fueron consideradas en el proceso de desarrollo.
7;¿Qué es un perfil de publicación (publishing profile) en Azure Bot Framework?;A. Se refiere al nivel de autenticación necesario para utilizar un chatbot.;B. Se refiere a la configuración utilizada para hacer despliegues de chatbots, incluyendo la infraestructura de Azure en la que se hospedan.;C. Se refiere al nivel de autorización necesario para desplegar un chatbot.;D. Se refiere a la configuración utilizada para hacer pruebas de chatbots, como paso previo a su despliegue en producción.;B;El uso de perfiles de publicación permite reutilizar los parámetros de despliegue para diferentes bots, reduciendo los tiempos de puesta en producción y las actualizaciones posteriores.
7;¿Qué aplicaciones tiene un chatbot en el sector de seguros?;A. El sector seguros no se beneficia de las ventajas de un chatbot.;B. Permite resolver dudas de los clientes, relacionadas con la cobertura de su póliza, el procedimiento para generar un parte o el estado de tramitación de un parte.;C. Se utilizan para que los agentes de seguros puedan determinar la probabilidad de venta de un seguro a un potencial cliente.;D. Se utilizan para atraer a nuevos clientes con mensajes promocionales, pero no tienen aplicaciones en los clientes existentes por la complejidad de los procesos de negocio en este sector.;B;El sector de seguros se beneficia considerablemente de los chatbots, porque se basa en actividades repetitivas y sujetas a un procedimiento, con información que cambia con cierta frecuencia. Entrenar a un equipo de personas para interactuar de la misma forma con clientes es costoso y susceptible de errores.
7;¿En qué lenguajes de programación puede escribirse el código fuente de los chatbots creados en Azure Bot Framework?;A. Python y Java.;B. C#/.NET, Node.js o Javascript.;C. C# exclusivamente.;D. Node.js o Java.;B;C#/.NET son tecnologías propias de Microsoft, mientras que Node.js o Javascript son lenguajes ampliamente reconocidos en la comunidad de desarrolladores. Por tanto, cualquiera de las dos opciones es igualmente recomendable para desarrollar chatbots.
7;¿Cuál de las siguientes no es una mejor práctica en el diseño de la experiencia conversacional?;A. Incluir un diálogo para pedir ayuda o finalizar la conversación.;B. Utilizar exactamente las mismas respuestas cada vez a una misma petición del usuario para no dar lugar a una interpretación incorrecta.;C. Mantener los diálogos breves.;D. Añadir variaciones a las respuestas;B;La variación de las respuestas (sin alterar su significado) genera en el usuario la sensación de estar conversando con un humano. Lo contrario genera rechazo, porque evidencia que se está hablando con una máquina.
7;¿Qué diferencia a un skill de un chatbot convencional?;A. Una habilidad o skill es el tipo de bot que interactúa directamente con el usuario.;B. Una habilidad o skill es un bot que no interactúa directamente con el usuario, sino que proporciona una funcionalidad determinada a otros bots.;C. Una habilidad o skill está programado en un lenguaje diferente que un bot convencional. A pesar de ellos, ambos son interoperables.;D. No existen diferencias, dado que se trata de términos utilizados para referirse al mismo tipo de tecnología conversacional.;B;Estos bots están especializados en determinadas tareas, y su uso por parte de bots convencionales facilita una arquitectura modular en la que las tareas pueden ser reutilizadas en diferentes escenarios.
7;Modelo E (P19) ¿Para qué se utiliza la opción “Conversational Boost”?;A. Mejorar el tiempo de respuesta del chatbot.;B. Proporcionar interacciones más atractivas y personalizadas.;C. Reaccionar a escenarios no cubiertos por temas existentes mediante el uso de fuentes externas.;D. Traducir las respuestas del chatbot a diferentes idiomas.;C;"Porque Boost conversations sirve para responder cuando ningún topic cubre la necesidad, usando una fuente externa (web/OneDrive/Bing); Tema 7, Copilot Studio → Respuestas generativas, pág. 16."
7;Modelo E (P20) ¿Para qué se utiliza “Create with Copilot”?;A. Generar temas automáticamente a partir de una descripción.;B. Entrenar el modelo de lenguaje del chatbot con nuevos datos.;C. Conectar el chatbot a API externas.;D. Diseñar la interfaz de usuario del chatbot.;A;"Porque Create with Copilot automatiza la creación de topics a partir de una descripción, generando nodos y flujo; Tema 7, Copilot Studio → Creación de topics, pág. 16."
7;Modelo E (P21) ¿Qué sucede cuando la solicitud no está cubierta por ningún tema en Copilot Studio?;A. El chatbot ignora la solicitud.;B. El chatbot muestra un mensaje de error.;C. El chatbot le pide al usuario que reformule la solicitud o la escala a un agente humano.;D. El chatbot busca información relevante en el sitio web de reserva.;C;"Porque si la petición no está en ningún topic, el bot pide reformular y, si sigue sin poder, escala a humano (topic Escalate); Tema 7, Copilot Studio → Creación de topics, pág. 15."
7;Modelo D (20) ¿Cuál es el propósito de la prevención de pérdida de datos (DLP) en Copilot Studio?;A. Proteger la información y minimizar el riesgo de fugas controlando el uso del copilot (p. ej. restringiendo canales o exigiendo autenticación).;B. Evitar que el chatbot se utilice con fines maliciosos.;C. Asegurar que las respuestas del chatbot cumplan con las normas de privacidad.;D. Hacer una copia de seguridad de los datos y la configuración del chatbot.;A;"Porque el tema explica que DLP se usa para evitar fugas limitando canales y/o haciendo obligatoria la autenticación; Tema 7, Protección frente a fugas de información (p. 19)."
7;Modelo D (21) ¿Para qué se utiliza la moderación de contenido en Copilot Studio?;A. Evitar que el chatbot genere contenido ofensivo o inapropiado.;"B. Asegurar mayor precisión de las respuestas (alto = más precisas; medio/bajo = más cobertura pero posible inexactitud).";C. Controlar la longitud y complejidad de las respuestas del chatbot.;D. Limitar el número de temas que el chatbot puede manejar.;B;"Porque “Content moderation” sirve para acotar el alcance/calidad: en High da respuestas más precisas, y en Medium/Low puede ser menos exacto; Tema 7, Respuestas generativas → Content moderation (p. 17)."
7;¿Cuál es el formato habitual de respuesta de las APIs de Azure Cognitive Services?;A. Texto;B. YAML;C. CSV;D. JSON;d;Estas APIs devuelven resultados estructurados normalmente en JSON.
7;¿Cuál es la principal ventaja de un buscador semántico implementado con Azure AI Search?;A. Menor latencia de respuesta;B. Menor espacio de almacenamiento de los contenidos;C. Mayor precisión de los resultados;D. No tiene ninguna ventaja sustancial respecto a un buscador tradicional;c;La búsqueda semántica mejora la relevancia al entender intención/similitud, no solo coincidencia literal.
7;¿El servicio Form Recognizer permite reconocer campos y valores sin necesidad de entrenar un modelo específico para nuestros documentos?;A. No, siempre es obligatorio entrenar un modelo específico;B. Sí, usando modelos preconstruidos/plantillas para ciertos tipos de documentos;C. Solo si los documentos están en formato audio;D. Solo para facturas y únicamente con entrenamiento;b;Es verdadero: puede extraer campos con capacidades preconstruidas en varios escenarios sin entrenamiento específico.
8;¿Cuál de las siguientes no es una característica del servicio Computer Vision?;A. Detección de objetos.;B. Clasificación de imágenes clínicas.;C. Reconocimiento de texto manuscrito e impreso.;D. Paleta de colores.;B;El servicio Computer Vision reconoce un amplio abanico de información contenida en una imagen. Sin embargo, es Azure AI Language quien puede realizar el análisis de textos (no imágenes) clínicas.
8;¿En qué se diferencian los servicios Computer Vision y Custom Vision?;A. En Computer Vision se proporcionan imágenes propias para reentrenar los modelos de acuerdo con categorías personalizadas.;B. En Custom Vision se proporcionan imágenes propias para reentrenar los modelos de acuerdo con categorías personalizadas.;C. No existen ninguna diferencia, son dos nombres utilizados para referirse al mismo servicio.;D. Custom Vision proporciona una mayor precisión en la información extraída, dado que utiliza modelos con mejores procesos de entrenamiento.;B;En efecto, Custom Vision permite extender la funcionalidad por defecto de Computer Vision para adaptarse a casos de uso personalizados en los que la categorización estándar no es suficiente.
8;¿Qué características deben tener las imágenes de entrenamiento de Custom Vision?;A. Deben tener el formato JPG.;B. Deben incluir diferentes tipos de iluminación, ángulos y fondos.;C. Deben tener una resolución adecuada, de al menos 1920x1080px.;D. Deben incluir el mismo tipo de iluminación, ángulos y fondos.;B;El uso de imágenes que varían en estos aspectos permite entrenar modelos más precisos para la clasificación de imágenes nuevas, dado que se considera un amplio abanico de posibles configuraciones.
8;¿Cuál de las siguientes no es una característica del servicio Face?;A. Detección de caras similares a una dada.;B. Incorporación de filtros de imagen a las caras detectadas para corregir circunstancias habituales, como por ejemplo los ojos cerrados.;C. Agrupación de imágenes con caras de aspecto similar.;D. Comprobación de que las caras mostradas en dos imágenes pertenecen a la misma persona.;B;En efecto, el servicio Face se centra exclusivamente en la detección y comparación de caras para diferentes propósitos, pero no realiza mejoras a la imagen original.
8;¿Qué atributos incluye el JSON de resultados devuelto por detect_with_url() en el servicio Face?;A. Solo indica que se trata de una cara, pero no aporta ningún dato adicional.;B. Edad, sexo y coordenadas de posición.;C. Coordenadas de posición.;D. Coordenadas de posición y sexo.;B;El JSON incorpora la edad aproximada de la persona, su sexo y las coordenadas del rectángulo que enmarca la cara encontrada en la imagen.
8;"El servicio Form Recognizer
permite reconocer campos y valores de un formulario sin necesidad de entrenar un modelo específico para nuestros documentos:";A. Falso.;B. Verdadero.;;;B;Se puede utilizar el General Document Model para extraer información de un documento en cualquier formato. Solo en caso de que los resultados no sean satisfactorios se recomienda entrenar modelos personalizados a partir de muestras de los tipos de documentos considerados.
8;¿Cuáles son los principales casos de uso de la funcionalidad de clasificación personalizada de textos en Azure AI Language?;A. Resumen de libros.;B. Categorización automática de correos o tiques y buscadores semánticos.;C. Creación de chatbots.;D. Integración en Power BI.;B;Mediante los modelos personalizados de clasificación, es posible automatizar la lectura de correos para determinar cómo deben gestionarse. También es posible asignar etiquetas a documentos internos de una organización para facilitar su recuperación mediante búsquedas semánticas.
8;¿En qué consiste la funcionalidad de detección de entidades en Azure AI Language?;A. Permite identificar contenido ofensivo en un texto y reemplazarlo por asteriscos.;B. Permite extraer las entidades clave de un texto, tales como lugares, fechas, cantidades, nombres o marcas.;C. Permite extraer nombres de personas que aparecen en el texto.;D. Permite extraer información personal o sensible detectada en el texto.;B;Estas entidades representan información valiosa para generar la respuesta a un mensaje o ejecutar acciones relacionadas con este.
8;¿Cuáles son las tecnologías de Power Platform en las que pueden integrarse servicios cognitivos de Azure?;A. Power Apps y Power BI.;B. Power Apps, Power BI y Power Automate.;C. Power Automate y Power BI.;D. Los servicios cognitivos de Azure no pueden integrarse en la Power Platform.;B;En efecto, los servicios cognitivos pueden integrarse en los flujos creados con Power Automate, en el análisis de datos realizado con Power BI o en las funcionalidades de aplicaciones desarrolladas con Power Apps.
8;¿Cuál de los siguientes tipos de información no es identificada por la funcionalidad de detección de información personal o sensible de Azure AI Language?;A. Direcciones postales.;B. Números de identificación de asociaciones regionales.;C. Fechas.;D. Puesto que ocupa un empleado en la organización.;B;La detección de información personal o sensible se centra en aquellos elementos que pueden comprometer la confidencialidad de datos o el cumplimiento regulatorio en una organización.
8;Mod e - p22 ¿Cuál de las siguientes opciones NO es una característica del servicio Azure AI Language?;A. Clasificación de imágenes.;B. Clasificación de textos.;C. Detección de entidades.;D. Detección de tono y opiniones.;A;Azure AI Language se centra en NLP (p.ej., clasificación de textos, detección de entidades, tono/opiniones), no en visión/imágenes (Tema 8, Ideas clave, págs. 31–36).
8;Mod e - p23 ¿Qué significa la sigla OCR en el contexto del servicio Form Recognizer?;A. Optical Character Recognition.;B. Object Categorization and Recognition.;C. Online Content Review.;D. Omnichannel Customer Relationship.;A;El tema indica que Form Recognizer “se basa en tecnología de reconocimiento de textos (OCR)”, cuyo acrónimo corresponde a Optical Character Recognition (Tema 8, Ideas clave, pág. 23).
8;Mod e - p24 ¿Qué servicio se especializa en el reconocimiento de rostros y atributos faciales?;A. Computer Vision.;B. Custom Vision.;C. Face.;D. Form Recognizer.;C;El tema define Face como el servicio que identifica caras y devuelve atributos faciales (sexo, edad, etc.), por eso es el específico para rostros (Tema 8, Ideas clave, págs. 18–19).
8;Mod d - p23 ¿Qué tipo de modelos se utilizan en el servicio de generación de resúmenes de Azure AI Language?;A. Modelos de aprendizaje automático supervisado.;B. Modelos de aprendizaje automático no supervisado.;C. Modelos de clustering.;D. Modelos de IA preentrenados.;D;El tema indica que la generación de resúmenes “utiliza modelos de IA preentrenados” (Tema 8 → Azure AI Language → Generación de resúmenes, pág. 36).
8;Mod e - p24 ¿Para qué se puede utilizar el servicio de text-to-speech de Azure Cognitive Services?;A. Para analizar el sentimiento de un texto.;B. Para convertir texto en audio con voces que suenan naturales.;C. Para traducir un texto a otro idioma.;D. Para identificar el idioma principal de un texto.;B;El tema explica que el servicio convierte texto a audio y que las voces suenan naturales (Tema 8 → Speech, pág. 38).
8;"Mod D - DESARROLLO: 2) ¿Qué función va a tener el recurso creado…?

az cognitiveservices account create --name <your-resource-name> --
resource-group <your-resource-group-name> --kind FormRecognizer --
sku <sku> --location <location> --yes
(Responder en 4 líneas)";"Crea un recurso de Azure Cognitive Services de tipo Form Recognizer. 
Su función es habilitar la API para analizar documentos (OCR + estructura). 
Permite extraer texto, tablas y pares clave/valor de PDFs/imágenes. 
Luego se usan su endpoint y key para llamar al servicio desde código. ";;;;A;Se muestra que el primer paso es crear el recurso con Azure CLI para luego obtener endpoint y key y consumir la API de Form Recognizer desde Python.
9;¿Cuáles son los dos aspectos clave del paradigma MLOps?;A. Uso de MLflow y registro de modelos.;B. Automatización de tareas repetitivas mediante pipelines y registro de experimentos.;C. Registro de experimentos y ejecuciones.;D. Operacionalización de modelos y uso de servicios cloud.;B;El uso de pipelines agiliza los procesos de MLOps y además reduce errores derivados de ejecutar tareas repetitivas de forma manual. El registro de experimentos permite encontrar más fácilmente el modelo óptimo.
9;MLflow es una plataforma MLOps open-source que puede desplegarse:;A. Solo en un data center, pero no en un proveedor de nube. Para implantar MLOps en nube, es necesario utilizar las plataformas proporcionadas por el proveedor.;B. En un data center o en cualquier proveedor de nube.;C. Solo en un entorno de computación en la nube.;D. En un data center o en AWS.;B;En efecto, MLflow puede desplegarse de forma local o en la nube. En el caso de AWS, existe una integración nativa, pero también puede funcionar correctamente en cualquier otro proveedor de nube que disponga de instancias de computación.
9;Las principales funciones de MLflow son:;A. Crear experimentos, registrar ejecuciones, entrenar modelos y desplegar modelos en endpoints para inferencia;B. Crear experimentos, registrar ejecuciones, comparar métricas de rendimiento, registrar modelos y desplegar modelos.;C. Crear experimentos, registrar ejecuciones, entrenar modelos y validar modelos, comparando las métricas de rendimiento entre ellos.;D. Crear experimentos y desplegar modelos.;B;Estas funciones garantizan que se dispone de trazas suficientes acerca de todo el proceso de creación de modelos. Además, la función de despliegue agiliza la puesta en producción de estos modelos.
9;La función mlflow.start_run() de MLflow se utiliza para:;A. Declarar un nuevo experimento.;B. Señalizar el inicio de una ejecución, de manera que todas las trazas registradas queden asociadas a este run.;C. Crear un nuevo experimento, si aún no existe.;D. Señalizar el inicio de un proceso de registro de modelos.;B;La llamada a esta función provoca que las trazas que se registren a continuación quedarán asociadas a una nueva ejecución ( run ).
9;La función log_artifact() de MLFlow puede utilizarse para:;A. Registrar métricas de rendimiento con valores numéricos.;B. Registrar imágenes generadas en el proceso de validación.;C. Registrar modelos en formato binario.;D. No es una función de MLflow.;B;En efecto, la llamada a esta función puede incluir como parámetro la ruta a un fichero de imagen previamente generado para que se incorpore al conjunto de trazas de la ejecución.
9;Para desplegar un servidor de inferencias en MLflow, es necesario especificar:;A. El identificador del experimento.;B. El identificador del run y el nombre del modelo.;C. El nombre del modelo.;D. El identificador del run ;B;Cada versión de un modelo está asociada a un run y un nombre, que se asigna en la llamada a log_model().
9;Para simplificar el despliegue de una arquitectura MLOps en SageMaker, se utiliza:;A. Fargate.;B. Cloud Development Kits.;C. S3.;D. RDS.;B;Los CDKs son paquetes de iniciación o quickstarts, que permiten a los ingenieros de nube desplegar rápidamente una arquitectura de servicios.
9;La función que permite registrar trazas con MLflow en SageMaker desde el código fuente es: ;A. mlflow.start_run();B. mlflow.set_tracking_uri() ;C. mlflow.load_model();C. mlflow.load_model();B;Esta es la función que permite especificar el destino de las trazas que se generen a continuación. Este es el único cambio en el código fuente para que MLflow funcione con AWS SageMaker. 
9;La plataforma de Azure DevOps puede utilizarse para desplegar la infraestructura necesaria a través de:;A. Una service connection y el servicio Azure Resource Manager (ARM).;B. Un service principal, una service connection y el servicio Azure Resource Manager (ARM).;C. Un service principal y el servicio Azure Resource Manager (ARM).;D. Un service principal, una service connection y el servicio RDS.;B;El service principal se encarga de la autenticación, la service connection proporciona la conexión a Azure y el ARM se encarga de la provisión de los recursos de infraestructura necesarios.
9;En la arquitectura MLOps de Google, Vertex Pipelines soporta de forma nativa:;A. KubeFlow Pipelines únicamente.;B. KubeFlow Pipelines y TensorFlow Extended.;C. TensorFlow Extended únicamente.;D. KubeFlow Pipelines y Keras Pipelines.;B;KubeFlow Pipelines se utiliza para desplegar modelos en Kubernetes, mientras que TFX proporciona una funcionalidad similar en TensorFlow.
9;Mod e - p25 ¿Cuál es la ventaja de utilizar contenedores Docker en MLOps?;A. Proporcionan un entorno reproducible y portátil… (encapsulan la ejecución del proceso en contenedores);B. Reducen el coste de ejecutar modelos de aprendizaje automático.;C. Eliminan la necesidad de escribir código.;D. Simplifican el proceso de recopilación de datos.;A;Porque el tema indica que la infraestructura de MLOps se explota con contenedores Docker especializados para ejecutar partes del proceso de forma consistente.
9;Mod e - p26 ¿Qué tipo de datos se pueden registrar en un registro de experimentos de MLflow?;A. Parámetros del modelo;B. Métricas de rendimiento;C. Artefactos, como archivos de modelo e imágenes;D. Todas las anteriores;D;Porque MLflow permite registrar parámetros (log_param), métricas (log_metric) y artefactos (log_artifact).
9;Mod e - p27 ¿Cuál de las siguientes opciones NO es un paso común en un pipeline de entrenamiento de MLOps?;A. Preparación de datos;B. Entrenamiento del modelo;C. Evaluación del modelo;D. Diseño de la interfaz de usuario de la aplicación;D;Porque los pipelines MLOps cubren preparación de datos, entrenamiento y validación/selección del modelo, no tareas de UI.
9;Mod d - p26 ¿Cuál es el objetivo principal de implementar MLOps en una organización?;A. Eliminar la necesidad de científicos de datos.;B. Acelerar el ciclo de vida del aprendizaje automático y mejorar la calidad y confiabilidad de los modelos de aprendizaje automático.;C. Reducir el coste de los recursos informáticos.;D. Aumentar la complejidad de los procesos de aprendizaje automático.;B;MLOps busca hacer repetible y controlado el ciclo de vida del modelo, automatizando tareas repetitivas y registrando resultados para elegir el modelo óptimo y mejorar iterativamente.
9;Mod d - p27 ¿Qué significa la sigla CI/CD en el contexto de MLOps?;A. Integración continua y entrega continua.;B. Clasificación e inferencia de datos;C. Creación y diseño de contenedores;D. Control e interpretación de datos;A;"El tema usa CI/CD como el entorno que dispara pipelines por commits y automatiza workflows (DevOps aplicado a MLOps); las siglas no se expanden en el texto, pero se usan con ese sentido."
9;"Mod D - DESARROLLO: 1) ¿Qué instrucción debe aparecer… para dar por concluida la ejecución actual del experimento en MLflow?

with mlflow.start_run():
train(sk_model, x_train, y_train)
...
(Responder en 4 líneas)";"Debe llamarse a la instrucción: mlflow.end_run(). 
Sirve para confirmar la finalización del run actual. 
Así se evita mezclar trazas/métricas entre ejecuciones distintas. 
Va justo después del bloque with mlflow.start_run(): ...";;;;A;En el material se indica explícitamente que es importante llamar a end_run() para confirmar el fin del run y evitar mezclar trazas entre ejecuciones.
10;¿Cuál de los siguientes NO es un caso de uso de IA en el sector sanitario?;A. Uso de chatbots para automatizar el diagnóstico del paciente o asistir a los profesionales médicos en esta labor.;B. Elección de proveedores de dispositivos médicos.;C. Sistemas de auditoría.;D. Gestión del embarazo.;B;Existe un amplio abanico de casos de uso de IA en el sector sanitario, generalmente relacionados con la identificación de patrones para fines predictivos o el uso de IA generativa para procesamiento de lenguaje natural.
10;¿Para qué se utiliza la IA en los robots quirúrgicos?;A. Para la identificación de los pacientes óptimos para la intervención.;B. Para identificar qué patrones del procedimiento quirúrgico producen mejores resultados e incrementar la precisión de las intervenciones.;C. Para la evaluación de la fatiga de los profesionales médicos que operan el robot.;D. Para proporcionar información precisa de posición al robot.;B;El análisis de los datos asociados a múltiples intervenciones previas facilita la extracción de patrones para mejorar los resultados de intervenciones futuras.
10;¿Qué tipos de enfermedades puede detectar la IA mediante el análisis de imágenes médicas?;A. Únicamente cardiovasculares.;B. Cardiovasculares, neurológicas, oncológicas.;C. Únicamente neurológicas.;D. Oncológicas, cardiovasculares o de naturaleza vírica.;B;En efecto, los estudios publicados indican que la IA puede detectar eficazmente enfermedades de tipo cardiovascular, neurológico u oncológico en imágenes médicas.
10;¿Cuál de los siguientes no es un beneficio del cloud para implantar IA en el sector sanitario?;A. Capacidad para escalar.;B. El acceso a los servicios a través de una consola web.;C. Garantías de seguridad.;D. Reutilización de modelos preentrenados.;B;Los proveedores de cloud disponen de grandes infraestructuras que permiten un escalado dinámico de la capacidad de computación, así como modelos de IA preentrenados que pueden adaptarse a casos de uso particulares, y unas mayores garantías de seguridad por sus inversiones en sistemas para prevenir incidentes.
10;¿En qué consiste el Project Health Insights de Microsoft Azure?;A. Detecta cáncer de mama a partir de imágenes médicas.;B. Utiliza dos modelos preentrenados para detección del cáncer y la asignación de pacientes a ensayos clínicos.;C. Es un chat conversacional para atender a pacientes.;D. Es una base de datos de tratamientos construida por un agente de IA.;B;En efecto, Azure lanzó este proyecto para generar modelos de IA que resuelvan ambas problemáticas. Estos modelos permiten mejorar la salud de la población y ahorrar costes a las organizaciones del sector sanitario.
10;¿Qué diferencia a MedLM de un LLM (large language model) convencional?;A. MedLM se utiliza para descubrir nuevos fármacos.;B. MedLM se utiliza para responder preguntas de carácter médico.;C. MedLM se utiliza para generar modelos predictivos de demanda de servicios sanitarios.;D. MedLM se utiliza como sistema de entrenamiento de chats conversacionales basados en modelos LLM.;B;MedLM es una colección de modelos conversacionales desarrollados por Google Cloud, que están especializados en temáticas del ámbito médico. Pueden utilizarse para construir chatbots inteligentes capaces de resolver dudas a pacientes.
10;¿Cómo se utiliza la IA para mejorar la extracción de crudo y gas?;A. Se utiliza para determinar las mejores técnicas de extracción.;B. Se utiliza identificar dónde se encuentran los yacimientos analizando datos de carácter geológico.;C. Se utiliza para determinar la calidad de la extracción, en lugar de utilizar procesos manuales que requieren presencia de expertos en el yacimiento.;D. No se utiliza la IA con este propósito.;B;La capacidad de los sistemas de IA para analizar grandes volúmenes de información es clave a la hora de encontrar los patrones característicos de una ubicación en la que existe un yacimiento.
10;¿Cuál son las principales aplicaciones de la IA en el ámbito de las energías renovables?;A. Identificar nuevas opciones de energías renovables.;B. Equilibrar oferta y demanda e identificar el momento idóneo para generar energía.;C. Ajustar el precio de estas energías para garantizar que se consuma la totalidad de la energía que se ha producido.;D. No se utiliza la IA en este ámbito.;B;La consecución de este equilibrio permite optimizar el proceso de producción y reducir sus costes, potenciando la competitividad de este tipo de energías respecto a las fuentes de energía tradicionales.
10;¿Qué aspectos de los proveedores de computación en la nube se capitalizan en el sector energético?;A. El acceso a los servicios a través de una consola web y el uso de APIs.;B. La captura de información en tiempo real, la disponibilidad de infraestructura en todas las geografías, la escalabilidad y sus servicios de análisis de datos.;C. La disponibilidad de los servicios en múltiples idiomas y la posibilidad de configurarlos a través de un SDK en Python.;D. Sus servicios de análisis de datos con modelos de IA preentrenados.;B;Es precisamente la integración de todos estos servicios la que posibilita la implementación ágil de sistemas que explotan la IA en este sector.
10;La aplicación de IA para el control de plagas permite:;A. Aumentar el consumo de pesticidas.;B. Reducir el consumo de pesticidas.;C. Descubrir nuevos tipos de plagas.;D. Evitar el consumo de pesticidas.;B;El análisis de imágenes de temperatura proporcionadas por los satélites permite anticipar la aparición de una plaga y focalizar el uso de pesticidas a la zona afectada.
10;Mod e - p28 ¿Qué es Azure Data Manager for Agriculture?;A. Una plataforma de trading de productos agrícolas.;B. Un sistema de control de plagas.;C. Una solución de Azure para gestionar datos en el sector agrícola.;D. Un chatbot para agricultores.;C;En agrotech, Azure ofrece Azure Data Manager for Agriculture como solución específica para gestionar/explotar datos del sector (Tema 10, 10.4, p. 25).
10;Mod e - p29 ¿Para qué se utiliza el chatbot Ama KrushAI?;A. Para predecir la producción de las cosechas.;B. Para detectar plagas en los cultivos.;C. Para proporcionar a los granjeros info sobre prácticas agrónomas, ayudas del gobierno y financiación.;D. Para controlar la temperatura del suelo.;C;En bots conversacionales de agrotech se indica que Ama KrushAI da consejos agrónomos, ayudas y financiación (Tema 10, 10.4, p. 25).
10;Mod e - p30 ¿Cuál de los siguientes es un ejemplo de chatbot en el sector agrotech?;A. Google Health.;B. FARMER.Chat.;C. Enlitic.;D. Arterys.;B;En agrotech se lista explícitamente FARMER.Chat como bot para granjeros (Tema 10, 10.4, p. 25).
10;Mod d - p29 ¿Qué es un robo-advisor?;A. Un robot que realiza tareas administrativas en un banco.;B. Un sistema de IA que proporciona asesoramiento financiero personalizado a los clientes.;C. Un chatbot que resuelve dudas de los clientes.;D. Un algoritmo que detecta fraudes.;B;En 10.5 se define “Robo-advisors” como robots que analizan perfil inversor + evolución del mercado para recomendar inversiones (p. 28).
10;Mod d - p30 ¿Cuál de los siguientes es un caso de uso común de la IA en el sector financiero?;A. Prevención de fraudes.;B. Gestión de recursos humanos.;C. Diseño de productos.;D. Marketing digital.;A;En 10.5 aparece “Prevención de fraude” como uno de los casos de uso más notables en finanzas (p. 27).